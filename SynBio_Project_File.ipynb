{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the test for initial commit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "print(\"Pandas imported successfully, version: \"+pd.__version__)\n",
    "import statsmodels as sm\n",
    "print(\"Statsmodels imported successfully, version: \"+sm.__version__)\n",
    "import plotly.graph_objects as go\n",
    "print(\"Plotly function imported succesfully\")\n",
    "import plotly.express as px\n",
    "print(\"Plotly express imported succesfully\")\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import plotly as py\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "print(\"Successful\")\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv('/Users/mazutislab/Desktop/SynBio/US_Accidents_May19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only needed data in the given dataset\n",
    "data_cleaned = data_all[[\"Severity\", \"Temperature(F)\", \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\", \"Wind_Speed(mph)\", \n",
    "                        \"Precipitation(in)\"]]\n",
    "data_cleaned.reset_index()\n",
    "type(data_cleaned)\n",
    "\n",
    "#Convert Temperature in Fahrenheit to Celsius\n",
    "def fahr_to_celsius(temp_fahr):\n",
    "    \"\"\"Convert Fahrenheit to Celsius and Return Celsius conversion of input\"\"\"\n",
    "    temp_celsius = (temp_fahr - 32) * 5 / 9\n",
    "    return temp_celsius\n",
    "\n",
    "data_cleaned[\"Temperature(\\u00b0C)\"] = (fahr_to_celsius(data_cleaned[\"Temperature(F)\"])).round(2)\n",
    "data_cleaned.drop(['Temperature(F)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Pressure in inches of mercury to mbar\n",
    "data_cleaned[\"Pressure(mbar)\"] = data_cleaned[\"Pressure(in)\"]*0.033863886666667*1000\n",
    "data_cleaned.drop(['Pressure(in)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Wind Speed in mph to kmh\n",
    "data_cleaned[\"Wind_Speed(kmh)\"] = data_cleaned[\"Wind_Speed(mph)\"]*1.609344\n",
    "data_cleaned.drop(['Wind_Speed(mph)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Precipitation in inches to mm\n",
    "data_cleaned[\"Precipitation(mm)\"] = data_cleaned[\"Precipitation(in)\"]*25.4\n",
    "data_cleaned.drop(['Precipitation(in)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Visibility in miles to km\n",
    "data_cleaned[\"Visibility(km)\"] = data_cleaned[\"Visibility(mi)\"]*1.609344\n",
    "data_cleaned.drop(['Visibility(mi)'], inplace = True, axis = 1)\n",
    "data_cleaned.head()\n",
    "\n",
    "\n",
    "\n",
    "data_cleaned = data_cleaned[data_cleaned['Severity'] >= 1]\n",
    "data_cleaned = data_cleaned.sort_values(by=['Severity'], ascending = True)\n",
    "data_cleaned.reset_index()\n",
    "data_cleaned.head()\n",
    "\n",
    "t_col = 'Temperature(\\u00b0C)'\n",
    "h_col = 'Humidity(%)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x=(data_cleaned['Severity']))])\n",
    "\n",
    "fig.show()\n",
    "\n",
    "#Frequency of severities\n",
    "Severity_frequency = {}\n",
    "\n",
    "for i, u in enumerate(range(0,5)):\n",
    "    Severity_frequency['Severity' + str(u)] = (data_cleaned[(data_cleaned['Severity']==i)]).shape[0]\n",
    "\n",
    "print(Severity_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Histogram Temperature\n",
    "hist_temperature = go.Figure(data=[go.Histogram(x=(data_cleaned[t_col]), nbinsx=30)])\n",
    "\n",
    "hist_temperature.update_layout(height = 450, width = 800,\n",
    "    xaxis_title=\"Temperature (\\u00b0C)\",\n",
    "    yaxis_title=\"Frequency\"\n",
    ")\n",
    "\n",
    "hist_temperature.show()\n",
    "\n",
    "\n",
    "\n",
    "#Lowest/Highest Temp\n",
    "print(\"Lowest temperature in dataset is \" + str((data_cleaned[t_col]).min()) + \" \\u00b0C\")\n",
    "\n",
    "print(\"Highest temperature in dataset is \" + str((data_cleaned[t_col]).max()) + \" \\u00b0C\")\n",
    "\n",
    "\n",
    "\n",
    "#Left and right member in the low temperature interval\n",
    "t_low1 = -70\n",
    "t_low2 = -55\n",
    "\n",
    "temperature_values_low = data_cleaned[t_col].between(t_low1, t_low2, inclusive = True)\n",
    "print(\"There are \" + str((data_cleaned[temperature_values_low]).shape[0]) + \n",
    "      \" temperature values between \" + str(t_low1) + \" and \" + str(t_low2) + \" \\u00b0C\")\n",
    "\n",
    "#Left member in the interval\n",
    "t_high1 = 55\n",
    "\n",
    "#Right number in the interval\n",
    "t_high2 = 80\n",
    "\n",
    "temperature_values_high = data_cleaned[t_col].between(t_high1, t_high2, inclusive = True)\n",
    "\n",
    "print(\"There are \" + str((data_cleaned[temperature_values_high]).shape[0]) + \n",
    "      \" temperature values between \" + str(t_high1) + \" and \" + str(t_high2) + \" \\u00b0C\")\n",
    "\n",
    "\n",
    "#Outliers (extremes) removal\n",
    "data_cleaned_bool = data_cleaned[t_col].between(-55, 55, inclusive = True)\n",
    "data_cleaned_temp = data_cleaned[data_cleaned_bool]\n",
    "print(str(((data_cleaned[data_cleaned[t_col] > 55]).shape[0])+((data_cleaned[data_cleaned[t_col] < -55]).shape[0])) + \n",
    "      \" measurements have been removed from the dataset \")\n",
    "data_cleaned.head()\n",
    "\n",
    "#Temperature Between Severity Groups Histograms\n",
    "\n",
    "#Severity 1\n",
    "\n",
    "sev1_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 1])[t_col])\n",
    "sev2_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 2])[t_col])\n",
    "sev3_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 3])[t_col])\n",
    "sev4_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 4])[t_col])\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=(\"Severity 1\",\"Severity 2\", \"Severity 3\", \"Severity 4\"))\n",
    "\n",
    "#Adding Traces\n",
    "fig.add_trace(go.Histogram(x=(sev1_temp), nbinsx=20), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=(sev2_temp), nbinsx=20), row=1, col=2)\n",
    "fig.add_trace(go.Histogram(x=(sev3_temp), nbinsx=20), row=2, col=1)\n",
    "fig.add_trace(go.Histogram(x=(sev4_temp), nbinsx=20), row=2, col=2)\n",
    "\n",
    "# Update xaxis properties\n",
    "fig.update_xaxes(title_text=\"Temperature \\u00b0C\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Temperature \\u00b0C\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Temperature \\u00b0C\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Temperature \\u00b0C\", row=2, col=2)\n",
    "\n",
    "# Update yaxis properties\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=2, col=2)\n",
    "\n",
    "# Update title and height\n",
    "fig.update_layout(title_text=\"Variable Temperature \\u00b0C histograms for each severity group\", height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed activate the code to remove outliers!\n",
    "\n",
    "#Outliers (extremes) removal\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "lower_value = int(input(\"Enter lowest included value in your chosen column for your new dataset \"))\n",
    "higher_value = int(input(\"Enter highest included value in your chosen column for your new dataset \"))\n",
    "data_cleaned_bool = data_cleaned[column_name].between(lower_value, higher_value, inclusive = True)\n",
    "data_cleaned_new = data_cleaned[data_cleaned_bool]\n",
    "print(str(((data_cleaned[data_cleaned[column_name] > higher_value]).shape[0])+\n",
    "          ((data_cleaned[data_cleaned[column_name] < lower_value]).shape[0])) + \n",
    "      \" measurements have been removed from the dataset \\n\")\n",
    "\n",
    "\n",
    "print(data_cleaned_new.head())\n",
    "\n",
    "print(\"\\n Your new compiled dataset is available under the name of data_cleaned_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Left and right member in the low temperature interval\n",
    "t_low1 = 85\n",
    "t_low2 = 1000\n",
    "\n",
    "temperature_values_low = data_cleaned_new['Visibility(km)'].between(t_low1, t_low2, inclusive = True)\n",
    "print(\"There are \" + str((data_cleaned_new[temperature_values_low]).shape[0]) + \n",
    "      \" temperature values between \" + str(t_low1) + \" and \" + str(t_low2) + \" \\u00b0C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Histogram Universal Code\n",
    "\n",
    "#Select dataset you want to work with (either data_cleaned or data_cleaned_new after removal of outliers)\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + str(list(data_cleaned.columns)) + \" : \")\n",
    "hist_bins = int(input(\"Enter number of bins in histogram \"))\n",
    "\n",
    "hist_variable = go.Figure(data=[go.Histogram(x=(data_input[column_name]), nbinsx=hist_bins)])\n",
    "\n",
    "hist_variable.update_layout(height = 450, width = 800,\n",
    "    xaxis_title=column_name,\n",
    "    yaxis_title=\"Frequency\"\n",
    ")\n",
    "\n",
    "hist_variable.show()\n",
    "\n",
    "\n",
    "#Lowest/Highest Value\n",
    "print(\"Lowest \" + column_name + \" in dataset is \" + str((data_input[column_name]).min()))\n",
    "\n",
    "print(\"Highest \" + column_name + \" in dataset is \" + str((data_input[column_name]).max()))\n",
    "\n",
    "\n",
    "\n",
    "#Histograms Between Severity Groups\n",
    "\n",
    "sev1 = ((data_input[(data_input['Severity']) == 1])[column_name])\n",
    "sev2 = ((data_input[(data_input['Severity']) == 2])[column_name])\n",
    "sev3 = ((data_input[(data_input['Severity']) == 3])[column_name])\n",
    "sev4 = ((data_input[(data_input['Severity']) == 4])[column_name])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=(\"Severity 1\",\"Severity 2\", \"Severity 3\", \"Severity 4\"))\n",
    "\n",
    "#Adding Traces\n",
    "fig.add_trace(go.Histogram(x=(sev1), nbinsx=hist_bins), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=(sev2), nbinsx=hist_bins), row=1, col=2)\n",
    "fig.add_trace(go.Histogram(x=(sev3), nbinsx=hist_bins), row=2, col=1)\n",
    "fig.add_trace(go.Histogram(x=(sev4), nbinsx=hist_bins), row=2, col=2)\n",
    "\n",
    "# Update xaxis properties\n",
    "fig.update_xaxes(title_text=column_name, row=1, col=1)\n",
    "fig.update_xaxes(title_text=column_name, row=1, col=2)\n",
    "fig.update_xaxes(title_text=column_name, row=2, col=1)\n",
    "fig.update_xaxes(title_text=column_name, row=2, col=2)\n",
    "\n",
    "# Update yaxis properties\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=2, col=2)\n",
    "\n",
    "# Update title and height\n",
    "fig.update_layout(title_text=\"Variable \" + column_name + \" histograms for each Severity group\", height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plot Temperature\n",
    "box_plot_temperature = px.box(data_cleaned_temp, x=\"Severity\", y=t_col)\n",
    "box_plot_temperature.show()\n",
    "Humidity (%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anderson-Darling Test Temperature\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "sev1_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 1])[t_col])\n",
    "sev1_temp_np = sev1_temp.to_numpy()\n",
    "sev1_temp_np = sev1_temp_np[np.logical_not(np.isnan(sev1_temp_np))]\n",
    "\n",
    "from scipy.stats import anderson\n",
    "\n",
    "#1\n",
    "result = anderson(sev1_temp_np)\n",
    "stat = round(result.statistic, 4)\n",
    "\n",
    "p = 0\n",
    "result_mat = []\n",
    "for i in range(len(result.critical_values)):\n",
    "    title = \"Severity \" + str(int((i+3)%(i+2)))\n",
    "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "    if result.statistic < result.critical_values[i]:\n",
    "        msg = 'Sample looks Gaussian (fail to reject H0)'\n",
    "    else:\n",
    "        msg = 'Sample does not look Gaussian (reject H0)'\n",
    "    result_mat.append([title, len(sev1_temp_np), stat, sl, cv, msg])\n",
    "\n",
    "trace = go.Table(\n",
    "    header=dict(values=['<b>Title<b>', '<b>Sample Size</b>', '<b>Statistic</b>', '<b>Significance Level</b>', '<b>Critical Value</b>', '<b>Comment</b>'],\n",
    "                line = dict(width=0),\n",
    "                fill = dict(color='rgba(42,63,95,0.8)'),\n",
    "                align = 'center',\n",
    "                font = dict(\n",
    "                    color = '#ffffff',\n",
    "                    size = 12\n",
    "                )),\n",
    "    cells=dict(values=np.array(result_mat).T,\n",
    "               line = dict(width=0),\n",
    "               fill = dict(color=[['#EBF0F8', '#ffffff', '#EBF0F8', '#ffffff', '#EBF0F8']]),\n",
    "               align = 'center',\n",
    "               height = 40),\n",
    "    columnwidth=[0.3, 0.25, 0.3, 0.25, 0.5])\n",
    "layout = dict(\n",
    "    height=300,\n",
    "    margin=dict(\n",
    "        l=5,\n",
    "        r=5,\n",
    "        t=30,\n",
    "        b=0\n",
    "    )\n",
    ")\n",
    "data = [trace]\n",
    "andar_table = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(andar_table, filename='anderson-darling-table')\n",
    "\n",
    "#2\n",
    "\n",
    "sev2_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 2])[t_col])\n",
    "sev2_temp_np = sev2_temp.to_numpy()\n",
    "sev2_temp_np = sev2_temp_np[np.logical_not(np.isnan(sev2_temp_np))]\n",
    "\n",
    "result = anderson(sev2_temp_np)\n",
    "stat = round(result.statistic, 4)\n",
    "\n",
    "p = 0\n",
    "result_mat = []\n",
    "for i in range(len(result.critical_values)):\n",
    "    title = \"Severity \" + str(int((i+6)%(i+4)))\n",
    "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "    if result.statistic < result.critical_values[i]:\n",
    "        msg = 'Sample looks Gaussian (fail to reject H0)'\n",
    "    else:\n",
    "        msg = 'Sample does not look Gaussian (reject H0)'\n",
    "    result_mat.append([title, len(sev2_temp_np), stat, sl, cv, msg])\n",
    "\n",
    "trace = go.Table(\n",
    "    header=dict(values=['<b>Title<b>', '<b>Sample Size</b>', '<b>Statistic</b>', '<b>Significance Level</b>', '<b>Critical Value</b>', '<b>Comment</b>'],\n",
    "                line = dict(width=0),\n",
    "                fill = dict(color='rgba(42,63,95,0.8)'),\n",
    "                align = 'center',\n",
    "                font = dict(\n",
    "                    color = '#ffffff',\n",
    "                    size = 12\n",
    "                )),\n",
    "    cells=dict(values=np.array(result_mat).T,\n",
    "               line = dict(width=0),\n",
    "               fill = dict(color=[['#EBF0F8', '#ffffff', '#EBF0F8', '#ffffff', '#EBF0F8']]),\n",
    "               align = 'center',\n",
    "               height = 40),\n",
    "    columnwidth=[0.3, 0.25, 0.3, 0.25, 0.5])\n",
    "layout = dict(\n",
    "    height=300,\n",
    "    margin=dict(\n",
    "        l=5,\n",
    "        r=5,\n",
    "        t=30,\n",
    "        b=0\n",
    "    )\n",
    ")\n",
    "data = [trace]\n",
    "andar_table = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(andar_table, filename='anderson-darling-table')\n",
    "\n",
    "#3\n",
    "\n",
    "sev3_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 3])[t_col])\n",
    "sev3_temp_np = sev3_temp.to_numpy()\n",
    "sev3_temp_np = sev3_temp_np[np.logical_not(np.isnan(sev3_temp_np))]\n",
    "\n",
    "result = anderson(sev3_temp_np)\n",
    "stat = round(result.statistic, 4)\n",
    "\n",
    "p = 0\n",
    "result_mat = []\n",
    "for i in range(len(result.critical_values)):\n",
    "    title = \"Severity \" + str(int((i+7)%(i+4)))\n",
    "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "    if result.statistic < result.critical_values[i]:\n",
    "        msg = 'Sample looks Gaussian (fail to reject H0)'\n",
    "    else:\n",
    "        msg = 'Sample does not look Gaussian (reject H0)'\n",
    "    result_mat.append([title, len(sev3_temp_np), stat, sl, cv, msg])\n",
    "\n",
    "trace = go.Table(\n",
    "    header=dict(values=['<b>Title<b>', '<b>Sample Size</b>', '<b>Statistic</b>', '<b>Significance Level</b>', '<b>Critical Value</b>', '<b>Comment</b>'],\n",
    "                line = dict(width=0),\n",
    "                fill = dict(color='rgba(42,63,95,0.8)'),\n",
    "                align = 'center',\n",
    "                font = dict(\n",
    "                    color = '#ffffff',\n",
    "                    size = 12\n",
    "                )),\n",
    "    cells=dict(values=np.array(result_mat).T,\n",
    "               line = dict(width=0),\n",
    "               fill = dict(color=[['#EBF0F8', '#ffffff', '#EBF0F8', '#ffffff', '#EBF0F8']]),\n",
    "               align = 'center',\n",
    "               height = 40),\n",
    "    columnwidth=[0.3, 0.25, 0.3, 0.25, 0.5])\n",
    "layout = dict(\n",
    "    height=300,\n",
    "    margin=dict(\n",
    "        l=5,\n",
    "        r=5,\n",
    "        t=30,\n",
    "        b=0\n",
    "    )\n",
    ")\n",
    "data = [trace]\n",
    "andar_table = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(andar_table, filename='anderson-darling-table')\n",
    "\n",
    "#4\n",
    "\n",
    "sev4_temp = ((data_cleaned_temp[(data_cleaned_temp['Severity']) == 4])[t_col])\n",
    "sev4_temp_np = sev4_temp.to_numpy()\n",
    "sev4_temp_np = sev4_temp_np[np.logical_not(np.isnan(sev4_temp_np))]\n",
    "\n",
    "result = anderson(sev4_temp_np)\n",
    "stat = round(result.statistic, 4)\n",
    "\n",
    "p = 0\n",
    "result_mat = []\n",
    "for i in range(len(result.critical_values)):\n",
    "    title = \"Severity \" + str(int((i+9)%(i+5)))\n",
    "    sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "    if result.statistic < result.critical_values[i]:\n",
    "        msg = 'Sample looks Gaussian (fail to reject H0)'\n",
    "    else:\n",
    "        msg = 'Sample does not look Gaussian (reject H0)'\n",
    "    result_mat.append([title, len(sev4_temp_np), stat, sl, cv, msg])\n",
    "\n",
    "trace = go.Table(\n",
    "    header=dict(values=['<b>Title<b>', '<b>Sample Size</b>', '<b>Statistic</b>', '<b>Significance Level</b>', '<b>Critical Value</b>', '<b>Comment</b>'],\n",
    "                line = dict(width=0),\n",
    "                fill = dict(color='rgba(42,63,95,0.8)'),\n",
    "                align = 'center',\n",
    "                font = dict(\n",
    "                    color = '#ffffff',\n",
    "                    size = 12\n",
    "                )),\n",
    "    cells=dict(values=np.array(result_mat).T,\n",
    "               line = dict(width=0),\n",
    "               fill = dict(color=[['#EBF0F8', '#ffffff', '#EBF0F8', '#ffffff', '#EBF0F8']]),\n",
    "               align = 'center',\n",
    "               height = 40),\n",
    "    columnwidth=[0.3, 0.25, 0.3, 0.25, 0.5])\n",
    "layout = dict(\n",
    "    height=300,\n",
    "    margin=dict(\n",
    "        l=5,\n",
    "        r=5,\n",
    "        t=30,\n",
    "        b=0\n",
    "    )\n",
    ")\n",
    "data = [trace]\n",
    "andar_table = dict(data=data, layout=layout)\n",
    "\n",
    "iplot(andar_table, filename='anderson-darling-table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# normality test\n",
    "stat, p = shapiro(Severity3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Sample does not look Gaussian (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anderson-Darling Test Universal\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import anderson\n",
    "\n",
    "#Choose dataset with what to work (data_cleaned or data_cleaned_new)\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "sev1_and = ((data_input[(data_input['Severity']) == 1])[column_name])\n",
    "Severity1 = sev1_and.to_numpy()\n",
    "Severity1 = Severity1[np.logical_not(np.isnan(Severity1))]\n",
    "\n",
    "sev2_and = ((data_input[(data_input['Severity']) == 2])[column_name])\n",
    "Severity2 = sev2_and.to_numpy()\n",
    "Severity2 = Severity2[np.logical_not(np.isnan(Severity2))]\n",
    "\n",
    "sev3_and = ((data_input[(data_input['Severity']) == 3])[column_name])\n",
    "Severity3 = sev3_and.to_numpy()\n",
    "Severity3 = Severity3[np.logical_not(np.isnan(Severity3))]\n",
    "\n",
    "sev4_and = ((data_input[(data_input['Severity']) == 4])[column_name])\n",
    "Severity4 = sev4_and.to_numpy()\n",
    "Severity4 = Severity4[np.logical_not(np.isnan(Severity4))]\n",
    "\n",
    "sev_list = [Severity1, Severity2, Severity3, Severity4]\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in sev_list:\n",
    "    result = anderson(i)\n",
    "    print(\"\\033[1m\" + (namestr(i, globals())[0] + ' Statistic: %.3f \\033[0m' % result.statistic))\n",
    "    while counter <1:\n",
    "        p = 0\n",
    "        for i in range(len(result.critical_values)):\n",
    "            sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "            if result.statistic < result.critical_values[i]:\n",
    "                print('Significance level: %.3f: Critical Value : %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n",
    "            else:\n",
    "                print('Significance level: %.3f: Critical Value : %.3f, data does not look normal (reject H0)' % (sl, cv))\n",
    "            counter += 1\n",
    "    counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "Severity1 = np.copy(sev1_temp_np)\n",
    "Severity2 = np.copy(sev2_temp_np)\n",
    "Severity3 = np.copy(sev3_temp_np)\n",
    "Severity4 = np.copy(sev4_temp_np)\n",
    "\n",
    "sev_all_temp = [Severity1, Severity2, Severity3, Severity4]\n",
    "sev_all_temp2 = [Severity2, Severity3, Severity4]\n",
    "\n",
    "statistics={}\n",
    "p_values={}\n",
    "\n",
    "    \n",
    "counter = 0\n",
    "\n",
    "for i in sev_all_temp:\n",
    "    while sev_all_temp2 and counter <1:\n",
    "        for u in sev_all_temp2:\n",
    "            (t,p) = ttest_ind(i, u)\n",
    "            if p == 1 or t == 0:\n",
    "                pass\n",
    "            else:\n",
    "                p_values[(namestr(i, globals())[1] + \" vs \" + namestr(u, globals())[1])]=p\n",
    "                statistics[(namestr(i, globals())[1] + \" vs \" + namestr(u, globals())[1])]=t\n",
    "                counter += 1\n",
    "    counter = 0\n",
    "    \n",
    "\n",
    "t_test_pd1 = pd.DataFrame.from_dict(statistics, orient='index')\n",
    "t_test_pd1.columns = ['Statistics']\n",
    "\n",
    "t_test_pd2 = pd.DataFrame.from_dict(p_values, orient='index')\n",
    "t_test_pd2.columns = ['P Value']\n",
    "\n",
    "result = t_test_pd1.join(t_test_pd2)\n",
    "\n",
    "result = result.drop([result.index[5], result.index[7], result.index[8]])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function\n",
    "#\n",
    "#list = [\"a\", \"b\", \"c\", \"d\"]\n",
    "#list2 = [\"b\", \"c\", \"d\"]\n",
    "#\n",
    "#counter = 0\n",
    "#\n",
    "#for i in list:\n",
    "#    while counter <1:\n",
    "#        for u in list2:\n",
    "#            if i == u:\n",
    "#                pass\n",
    "#            else:\n",
    "#                print(i+u) \n",
    "#            counter += 1\n",
    "#    counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "z_statistics={}\n",
    "z_p_values={}\n",
    "\n",
    "    \n",
    "counter = 0\n",
    "\n",
    "for i in sev_all_temp:\n",
    "    while sev_all_temp2 and counter <1:\n",
    "        for u in sev_all_temp2:\n",
    "            ztest, pval = stests.ztest(i, u, value=0, alternative='two-sided')\n",
    "            if pval == 1 or ztest == 0:\n",
    "                pass\n",
    "            else:\n",
    "                z_p_values[namestr(i, globals())[1]+ \" vs \" + namestr(u, globals())[1]]=pval\n",
    "                z_statistics[namestr(i, globals())[1]+ \" vs \" + namestr(u, globals())[1]]=ztest\n",
    "                counter += 1\n",
    "    counter = 0\n",
    "    \n",
    "\n",
    "z_test_pd1 = pd.DataFrame.from_dict(z_statistics, orient='index')\n",
    "z_test_pd1.columns = ['Z Statistics']\n",
    "\n",
    "z_test_pd2 = pd.DataFrame.from_dict(z_p_values, orient='index')\n",
    "z_test_pd2.columns = ['Z P Value']\n",
    "\n",
    "result_z = z_test_pd1.join(z_test_pd2)\n",
    "\n",
    "result_z = result_z.drop([result_z.index[5], result_z.index[7], result_z.index[8]])\n",
    "print(result_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "#ANOVA with outliers\n",
    "\n",
    "F, p = stats.f_oneway(sev1_temp, sev2_temp, sev3_temp, sev4_temp)\n",
    "print(\"ANOVA with outliers - p-value : \", p)\n",
    "print(\"ANOVA with outliers - F- value:\", F)\n",
    "    \n",
    "    \n",
    "#ANOVA after removing outliers\n",
    "\n",
    "data_new = data_cleaned[data_cleaned[t_col].between(-30, 30, inclusive=True)]\n",
    "data_new = data_new.dropna()\n",
    "sev1_new = data_new[data_new['Severity'] == 1]\n",
    "sev1_new = sev1_new[t_col]\n",
    "sev2_new = data_new[data_new['Severity'] == 2]\n",
    "sev2_new = sev2_new[t_col]\n",
    "sev3_new = data_new[data_new['Severity'] == 3]\n",
    "sev3_new = sev3_new[t_col]\n",
    "sev4_new = data_new[data_new['Severity'] == 4]\n",
    "sev4_new = sev4_new[t_col]\n",
    "\n",
    "\n",
    "F, p = stats.f_oneway(sev1_new, sev2_new, sev3_new, sev4_new)\n",
    "print(\"ANOVA removed outliers - p-value : \", p)\n",
    "print(\"ANOVA removed outliers - F- value:\", F)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kruskal-Wallis Test\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "stat, p = kruskal(sev1_temp, sev2_temp, sev3_temp, sev4_temp)\n",
    "print(\"Kruskal-Wallis with outliers - p-value : \", p)\n",
    "print(\"Kruskal-Wallis with outliers - Statistics:\", stat)\n",
    "\n",
    "stat, p = kruskal(sev1_new, sev2_new, sev3_new, sev4_new)\n",
    "print(\"Kruskal-Wallis removed outliers - p-value : \", p)\n",
    "print(\"Kruskal-Wallis removed outliers - Statistics:\", stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_sev_temp = data_cleaned_temp[['Severity', t_col]]\n",
    "                          \n",
    "data_sev_temp = data_sev_temp.dropna()\n",
    "\n",
    "data_sev_temp = data_sev_temp.sort_values(by=['Severity'])\n",
    "\n",
    "data_sev_temp2 = data_sev_temp.drop(columns='Severity')\n",
    "\n",
    "data_sev_temp = (data_sev_temp['Severity']).to_numpy()\n",
    "\n",
    "#Ordinal Logistic Regression\n",
    "\n",
    "from bevel.linear_ordinal_regression import OrderedLogit\n",
    "\n",
    "ls = OrderedLogit()\n",
    "ls.fit(data_sev_temp2, data_sev_temp)\n",
    "\n",
    "ls.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
