{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the test for initial commit!\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the test for initial commit!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas imported successfully, version: 0.25.1\n",
      "Statsmodels imported successfully, version: 0.10.1\n",
      "Plotly function imported succesfully\n",
      "Plotly express imported succesfully\n",
      "Numpy imported successfully, version: 1.17.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"Pandas imported successfully, version: \"+pd.__version__)\n",
    "import statsmodels as sm\n",
    "print(\"Statsmodels imported successfully, version: \"+sm.__version__)\n",
    "\n",
    "#Plotly packages\n",
    "import plotly.graph_objects as go\n",
    "print(\"Plotly function imported succesfully\")\n",
    "import plotly.express as px\n",
    "print(\"Plotly express imported succesfully\")\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "#Matplotlib packages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Numpy + Statistics\n",
    "import numpy as np\n",
    "print(\"Numpy imported successfully, version: \"+np.__version__)\n",
    "\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "#Define needed function in the code\n",
    "def namestr(obj, namespace):\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset\n",
    "\n",
    "data_all = pd.read_csv('/Users/mazutislab/Desktop/SynBio/US_Accidents_May19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing max display columns, in order to see all columns\n",
    "pd.set_option('display.max_columns', 50)\n",
    "data_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting only needed data in the given dataset\n",
    "data_cleaned = data_all[[\"Severity\", \"Temperature(F)\", \"Humidity(%)\", \"Pressure(in)\", \"Visibility(mi)\", \"Wind_Speed(mph)\", \n",
    "                        \"Precipitation(in)\"]]\n",
    "data_cleaned.reset_index()\n",
    "type(data_cleaned)\n",
    "\n",
    "#Convert Temperature in Fahrenheit to Celsius\n",
    "def fahr_to_celsius(temp_fahr):\n",
    "    \"\"\"Convert Fahrenheit to Celsius and Return Celsius conversion of input\"\"\"\n",
    "    temp_celsius = (temp_fahr - 32) * 5 / 9\n",
    "    return temp_celsius\n",
    "\n",
    "data_cleaned[\"Temperature(C)\"] = (fahr_to_celsius(data_cleaned[\"Temperature(F)\"])).round(2)\n",
    "data_cleaned.drop(['Temperature(F)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Pressure in inches of mercury to mbar\n",
    "data_cleaned[\"Pressure(mbar)\"] = data_cleaned[\"Pressure(in)\"]*0.033863886666667*1000\n",
    "data_cleaned.drop(['Pressure(in)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Wind Speed in mph to kmh\n",
    "data_cleaned[\"Wind_Speed(kmh)\"] = data_cleaned[\"Wind_Speed(mph)\"]*1.609344\n",
    "data_cleaned.drop(['Wind_Speed(mph)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Precipitation in inches to mm\n",
    "data_cleaned[\"Precipitation(mm)\"] = data_cleaned[\"Precipitation(in)\"]*25.4\n",
    "data_cleaned.drop(['Precipitation(in)'], inplace = True, axis = 1)\n",
    "\n",
    "#Convert Visibility in miles to km\n",
    "data_cleaned[\"Visibility(km)\"] = data_cleaned[\"Visibility(mi)\"]*1.609344\n",
    "data_cleaned.drop(['Visibility(mi)'], inplace = True, axis = 1)\n",
    "data_cleaned.head()\n",
    "\n",
    "#Slice data, so that Severity >= 1\n",
    "data_cleaned = data_cleaned[data_cleaned['Severity'] >= 1]\n",
    "data_cleaned = data_cleaned.sort_values(by=['Severity'], ascending = True)\n",
    "data_cleaned.reset_index()\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive Statistics\n",
    "\n",
    "data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Histogram for Severity groups\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(x=(data_cleaned['Severity']))])\n",
    "\n",
    "fig.show()\n",
    "\n",
    "#Frequency of severities\n",
    "Severity_frequency = {}\n",
    "\n",
    "for i, u in enumerate(range(0,5)):\n",
    "    Severity_frequency['Severity' + str(u)] = (data_cleaned[(data_cleaned['Severity']==i)]).shape[0]\n",
    "\n",
    "print(Severity_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset slicing function - Universal - for outliers removal\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "lower_value = int(input(\"Enter lowest included value in your chosen column for your new dataset \"))\n",
    "higher_value = int(input(\"Enter highest included value in your chosen column for your new dataset \"))\n",
    "data_cleaned_bool = data_cleaned[column_name].between(lower_value, higher_value, inclusive = True)\n",
    "data_cleaned_new = data_cleaned[data_cleaned_bool]\n",
    "print(str(((data_cleaned[data_cleaned[column_name] > higher_value]).shape[0])+\n",
    "          ((data_cleaned[data_cleaned[column_name] < lower_value]).shape[0])) + \n",
    "      \" measurements have been removed from the dataset \\n\")\n",
    "\n",
    "\n",
    "print(data_cleaned_new.head())\n",
    "\n",
    "print(\"\\n Your new compiled dataset is available under the name of data_cleaned_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to check the number of values in defined interval\n",
    "\n",
    "#Select dataset (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + str(list(data_cleaned.columns)) \n",
    "                    + \" : \")\n",
    "#Select values\n",
    "value_1 = int(input(\"Select lower interval value: \"))\n",
    "value_2 = int(input(\"Select higher interval value: \"))\n",
    "\n",
    "values_in_interval = data_input[column_name].between(value_1, value_2, inclusive = True)\n",
    "print(\"\\033[1m There are \" + str((data_input[values_in_interval]).shape[0]) + \" \" + str(column_name) +\n",
    "      \" values between \" + str(value_1) + \" and \" + str(value_2) + \" in the given data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Histogram Universal Code\n",
    "\n",
    "#Select dataset you want to work with (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + str(list(data_cleaned.columns)) + \" : \")\n",
    "hist_bins = int(input(\"Enter number of bins in histogram \"))\n",
    "\n",
    "hist_variable = go.Figure(data=[go.Histogram(x=(data_input[column_name]), nbinsx=hist_bins)])\n",
    "\n",
    "hist_variable.update_layout(height = 450, width = 800,\n",
    "    xaxis_title=column_name,\n",
    "    yaxis_title=\"Frequency\"\n",
    ")\n",
    "\n",
    "hist_variable.show()\n",
    "\n",
    "\n",
    "#Lowest/Highest Value\n",
    "print(\"Lowest \" + column_name + \" in dataset is \" + str((data_input[column_name]).min()))\n",
    "\n",
    "print(\"Highest \" + column_name + \" in dataset is \" + str((data_input[column_name]).max()))\n",
    "\n",
    "\n",
    "\n",
    "#Histograms Between Severity Groups\n",
    "\n",
    "sev1 = ((data_input[(data_input['Severity']) == 1])[column_name])\n",
    "sev2 = ((data_input[(data_input['Severity']) == 2])[column_name])\n",
    "sev3 = ((data_input[(data_input['Severity']) == 3])[column_name])\n",
    "sev4 = ((data_input[(data_input['Severity']) == 4])[column_name])\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=(\"Severity 1\",\"Severity 2\", \"Severity 3\", \"Severity 4\"))\n",
    "\n",
    "#Adding Traces\n",
    "fig.add_trace(go.Histogram(x=(sev1), nbinsx=hist_bins), row=1, col=1)\n",
    "fig.add_trace(go.Histogram(x=(sev2), nbinsx=hist_bins), row=1, col=2)\n",
    "fig.add_trace(go.Histogram(x=(sev3), nbinsx=hist_bins), row=2, col=1)\n",
    "fig.add_trace(go.Histogram(x=(sev4), nbinsx=hist_bins), row=2, col=2)\n",
    "\n",
    "# Update xaxis properties\n",
    "fig.update_xaxes(title_text=column_name, row=1, col=1)\n",
    "fig.update_xaxes(title_text=column_name, row=1, col=2)\n",
    "fig.update_xaxes(title_text=column_name, row=2, col=1)\n",
    "fig.update_xaxes(title_text=column_name, row=2, col=2)\n",
    "\n",
    "# Update yaxis properties\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=2, col=2)\n",
    "\n",
    "# Update title and height\n",
    "fig.update_layout(title_text=\"Variable \" + column_name + \" histograms for each Severity group\", height=800)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plot Universal\n",
    "\n",
    "#Choose data input (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "box_plot_temperature = px.box(data_input, x=\"Severity\", y=column_name)\n",
    "box_plot_temperature.show()\n",
    "\n",
    "\n",
    "#Median + Mean Calculation for displaying with box plots\n",
    "Median_results = {}\n",
    "Mean_results = {}\n",
    "sd_results = {}\n",
    "sem_results= {}\n",
    "\n",
    "for i, u in enumerate(range(1,5), 1):\n",
    "    Median_results['Severity' + str(u)] = (((data_input[data_input['Severity'] == i])[column_name]).median())\n",
    "    Mean_results['Severity' + str(u)] = (((data_input[data_input['Severity'] == i])[column_name]).mean())\n",
    "    sd_results['Severity' + str(u)] = (((data_input[data_input['Severity'] == i])[column_name]).std())\n",
    "    sem_results['Severity' + str(u)] = (((data_input[data_input['Severity'] == i])[column_name]).sem())\n",
    "\n",
    "    \n",
    "Mean_pd = pd.DataFrame.from_dict(Mean_results, orient='index')\n",
    "Mean_pd.columns = ['Mean']\n",
    "\n",
    "Median_pd = pd.DataFrame.from_dict(Median_results, orient='index')\n",
    "Median_pd.columns = ['Median']\n",
    "\n",
    "sd_pd = pd.DataFrame.from_dict(sd_results, orient='index')\n",
    "sd_pd.columns = ['Standard Deviation']\n",
    "\n",
    "sem_pd = pd.DataFrame.from_dict(sem_results, orient = 'index')\n",
    "sem_pd.columns = ['Standard Error']\n",
    "\n",
    "result = Mean_pd.join(Median_pd)\n",
    "\n",
    "result2 = result.join(sd_pd)\n",
    "\n",
    "result_final = result2.join(sem_pd)\n",
    "\n",
    "print(result_final)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anderson-Darling Test Universal\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import anderson\n",
    "\n",
    "#Choose data input (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "#Get numpy arrays of variable values for each Severity groups\n",
    "\n",
    "sev1_and = ((data_input[(data_input['Severity']) == 1])[column_name])\n",
    "Severity1 = sev1_and.to_numpy()\n",
    "Severity1 = Severity1[np.logical_not(np.isnan(Severity1))]\n",
    "\n",
    "sev2_and = ((data_input[(data_input['Severity']) == 2])[column_name])\n",
    "Severity2 = sev2_and.to_numpy()\n",
    "Severity2 = Severity2[np.logical_not(np.isnan(Severity2))]\n",
    "\n",
    "sev3_and = ((data_input[(data_input['Severity']) == 3])[column_name])\n",
    "Severity3 = sev3_and.to_numpy()\n",
    "Severity3 = Severity3[np.logical_not(np.isnan(Severity3))]\n",
    "\n",
    "sev4_and = ((data_input[(data_input['Severity']) == 4])[column_name])\n",
    "Severity4 = sev4_and.to_numpy()\n",
    "Severity4 = Severity4[np.logical_not(np.isnan(Severity4))]\n",
    "\n",
    "sev_list = [Severity1, Severity2, Severity3, Severity4]\n",
    "\n",
    "#Element-wise iteration through all Severity groups\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in sev_list:\n",
    "    result = anderson(i)\n",
    "    print(\"\\033[1m\" + (namestr(i, globals())[0] + ' Statistic: %.3f \\033[0m' % result.statistic))\n",
    "    while counter <1:\n",
    "        p = 0\n",
    "        for i in range(len(result.critical_values)):\n",
    "            sl, cv = result.significance_level[i], result.critical_values[i]\n",
    "            if result.statistic < result.critical_values[i]:\n",
    "                print('Significance level: %.3f: Critical Value : %.3f, data looks normal (fail to reject H0)' % (sl, cv))\n",
    "            else:\n",
    "                print('Significance level: %.3f: Critical Value : %.3f, data does not look normal (reject H0)' % (sl, cv))\n",
    "            counter += 1\n",
    "    counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ANOVA universal\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "#Choose data input (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "\n",
    "#Get numpy arrays of variable values for each Severity groups\n",
    "\n",
    "sev1_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 1])[column_name])\n",
    "Severity1_no_outliers = sev1_anova_no_outliers.to_numpy()\n",
    "Severity1_no_outliers = Severity1_no_outliers[np.logical_not(np.isnan(Severity1_no_outliers))]\n",
    "\n",
    "sev2_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 2])[column_name])\n",
    "Severity2_no_outliers = sev2_anova_no_outliers.to_numpy()\n",
    "Severity2_no_outliers = Severity2_no_outliers[np.logical_not(np.isnan(Severity2_no_outliers))]\n",
    "\n",
    "sev3_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 3])[column_name])\n",
    "Severity3_no_outliers = sev3_anova_no_outliers.to_numpy()\n",
    "Severity3_no_outliers = Severity3_no_outliers[np.logical_not(np.isnan(Severity3_no_outliers))]\n",
    "\n",
    "sev4_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 4])[column_name])\n",
    "Severity4_no_outliers = sev4_anova_no_outliers.to_numpy()\n",
    "Severity4_no_outliers = Severity4_no_outliers[np.logical_not(np.isnan(Severity4_no_outliers))]\n",
    "\n",
    "#ANOVA test\n",
    "\n",
    "F, p = stats.f_oneway(Severity1_no_outliers, Severity2_no_outliers, Severity3_no_outliers, Severity4_no_outliers)\n",
    "print(str(column_name) + ' variable ANOVA value F is equal to ' + str(F))\n",
    "print(str(column_name) + ' variable ANOVA value p is equal to ' + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Kruskal Wallis Universal\n",
    "\n",
    "\n",
    "#Choose data input (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "\n",
    "#Get numpy arrays of variable values for each Severity groups\n",
    "\n",
    "sev1_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 1])[column_name])\n",
    "Severity1_no_outliers = sev1_anova_no_outliers.to_numpy()\n",
    "Severity1_no_outliers = Severity1_no_outliers[np.logical_not(np.isnan(Severity1_no_outliers))]\n",
    "\n",
    "sev2_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 2])[column_name])\n",
    "Severity2_no_outliers = sev2_anova_no_outliers.to_numpy()\n",
    "Severity2_no_outliers = Severity2_no_outliers[np.logical_not(np.isnan(Severity2_no_outliers))]\n",
    "\n",
    "sev3_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 3])[column_name])\n",
    "Severity3_no_outliers = sev3_anova_no_outliers.to_numpy()\n",
    "Severity3_no_outliers = Severity3_no_outliers[np.logical_not(np.isnan(Severity3_no_outliers))]\n",
    "\n",
    "sev4_anova_no_outliers = ((data_cleaned_new[(data_cleaned_new['Severity']) == 4])[column_name])\n",
    "Severity4_no_outliers = sev4_anova_no_outliers.to_numpy()\n",
    "Severity4_no_outliers = Severity4_no_outliers[np.logical_not(np.isnan(Severity4_no_outliers))]\n",
    "\n",
    "#Kruskal-Wallis test\n",
    "\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "stat, p = kruskal(Severity1_no_outliers, Severity2_no_outliers, Severity3_no_outliers, Severity4_no_outliers)\n",
    "print(str(column_name) + ' variable Kruskal-Wallis Statistics value is equal to ' + str(stat))\n",
    "print(str(column_name) + ' variable Kruskal-Wallis p value is equal to ' + str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Z-test Universal\n",
    "\n",
    "from statsmodels.stats import weightstats as stests\n",
    "\n",
    "#Choose data input (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "    \n",
    "#Get numpy arrays of variable values for each Severity groups\n",
    "\n",
    "sev1_and = ((data_input[(data_input['Severity']) == 1])[column_name])\n",
    "Severity1 = sev1_and.to_numpy()\n",
    "Severity1 = Severity1[np.logical_not(np.isnan(Severity1))]\n",
    "\n",
    "sev2_and = ((data_input[(data_input['Severity']) == 2])[column_name])\n",
    "Severity2 = sev2_and.to_numpy()\n",
    "Severity2 = Severity2[np.logical_not(np.isnan(Severity2))]\n",
    "\n",
    "sev3_and = ((data_input[(data_input['Severity']) == 3])[column_name])\n",
    "Severity3 = sev3_and.to_numpy()\n",
    "Severity3 = Severity3[np.logical_not(np.isnan(Severity3))]\n",
    "\n",
    "sev4_and = ((data_input[(data_input['Severity']) == 4])[column_name])\n",
    "Severity4 = sev4_and.to_numpy()\n",
    "Severity4 = Severity4[np.logical_not(np.isnan(Severity4))]\n",
    "\n",
    "\n",
    "sev_all = [Severity1, Severity2, Severity3, Severity4]\n",
    "sev_all2 = [Severity2, Severity3, Severity4]\n",
    "\n",
    "#Create new dictionaries for z test\n",
    "\n",
    "z_statistics={}\n",
    "z_p_values={}\n",
    "\n",
    "\n",
    "#Element-wise iteration with all Severity groups\n",
    "counter = 0\n",
    "\n",
    "for i in sev_all:\n",
    "    while sev_all2 and counter <1:\n",
    "        for u in sev_all2:\n",
    "            ztest, pval = stests.ztest(i, u, value=0, alternative='two-sided')\n",
    "            if pval == 1 or ztest == 0:\n",
    "                pass\n",
    "            else:\n",
    "                z_p_values[namestr(i, globals())[1]+ \" vs \" + namestr(u, globals())[1]]=pval\n",
    "                z_statistics[namestr(i, globals())[1]+ \" vs \" + namestr(u, globals())[1]]=ztest\n",
    "                counter += 1\n",
    "    counter = 0\n",
    "    \n",
    "\n",
    "z_test_pd1 = pd.DataFrame.from_dict(z_statistics, orient='index')\n",
    "z_test_pd1.columns = ['Z Statistics']\n",
    "\n",
    "z_test_pd2 = pd.DataFrame.from_dict(z_p_values, orient='index')\n",
    "z_test_pd2.columns = ['Z P Value']\n",
    "\n",
    "result_z = z_test_pd1.join(z_test_pd2)\n",
    "\n",
    "result_z = result_z.drop([result_z.index[5], result_z.index[7], result_z.index[8]])\n",
    "print(result_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Mann Whitney U non parametric\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "\n",
    "#Choose data input (data_cleaned or data_cleaned_new [from slicing code])\n",
    "data_input = data_cleaned_new\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "sev1_and = ((data_input[(data_input['Severity']) == 1])[column_name])\n",
    "Severity1 = sev1_and.to_numpy()\n",
    "Severity1 = Severity1[np.logical_not(np.isnan(Severity1))]\n",
    "\n",
    "sev2_and = ((data_input[(data_input['Severity']) == 2])[column_name])\n",
    "Severity2 = sev2_and.to_numpy()\n",
    "Severity2 = Severity2[np.logical_not(np.isnan(Severity2))]\n",
    "\n",
    "sev3_and = ((data_input[(data_input['Severity']) == 3])[column_name])\n",
    "Severity3 = sev3_and.to_numpy()\n",
    "Severity3 = Severity3[np.logical_not(np.isnan(Severity3))]\n",
    "\n",
    "sev4_and = ((data_input[(data_input['Severity']) == 4])[column_name])\n",
    "Severity4 = sev4_and.to_numpy()\n",
    "Severity4 = Severity4[np.logical_not(np.isnan(Severity4))]\n",
    "\n",
    "\n",
    "sev_all = [Severity1, Severity2, Severity3, Severity4]\n",
    "sev_all2 = [Severity2, Severity3, Severity4]\n",
    "\n",
    "\n",
    "#U TEST\n",
    "\n",
    "#Create empty dictonaries\n",
    "U_stat_values={}\n",
    "U_p_values={}\n",
    "    \n",
    "    \n",
    "#Iterate element-wise\n",
    "counter = 0\n",
    "\n",
    "for i in sev_all:\n",
    "    while counter <1:\n",
    "        for u in sev_all2:\n",
    "            stat, p = mannwhitneyu(i, u)\n",
    "            if pval == 1 or ztest == 0:\n",
    "                pass\n",
    "            else:\n",
    "                U_p_values[namestr(i, globals())[1]+ \" vs \" + namestr(u, globals())[1]]=p\n",
    "                U_stat_values[namestr(i, globals())[1]+ \" vs \" + namestr(u, globals())[1]]=stat\n",
    "                counter += 1\n",
    "    counter = 0\n",
    "    \n",
    "\n",
    "U_stat_pd1 = pd.DataFrame.from_dict(U_stat_values, orient='index')\n",
    "U_stat_pd1.columns = ['Statistics']\n",
    "\n",
    "U_p_pd2 = pd.DataFrame.from_dict(U_p_values, orient='index')\n",
    "U_p_pd2.columns = ['P Value']\n",
    "\n",
    "result_U = U_stat_pd1.join(U_p_pd2)\n",
    "\n",
    "result_U = result_U.drop([result_U.index[3], result_U.index[6], result_U.index[8], result_U.index[9]])\n",
    "print(result_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function (I want to leave it here, in case I need it later)\n",
    "#\n",
    "#list = [\"a\", \"b\", \"c\", \"d\"]\n",
    "#list2 = [\"b\", \"c\", \"d\"]\n",
    "#\n",
    "#counter = 0\n",
    "#\n",
    "#for i in list:\n",
    "#    while counter <1:\n",
    "#        for u in list2:\n",
    "#            if i == u:\n",
    "#                pass\n",
    "#            else:\n",
    "#                print(i+u) \n",
    "#            counter += 1\n",
    "#    counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning data_set for ordinal regression (choosing only specific values)\n",
    "\n",
    "data_cleaned_final = data_cleaned[data_cleaned['Temperature(C)'].between(-55, 50, inclusive = True)]\n",
    "\n",
    "data_cleaned_final = data_cleaned_final[data_cleaned_final['Pressure(mbar)'].between(950, 1055, inclusive = True)]\n",
    "\n",
    "data_cleaned_final = data_cleaned_final[data_cleaned_final['Wind_Speed(kmh)'].between(0, 150, inclusive = True)]\n",
    "\n",
    "data_cleaned_final = data_cleaned_final[data_cleaned_final['Visibility(km)'].between(0, 80, inclusive = True)]\n",
    "\n",
    "print(data_cleaned_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "data_sev_temp = data_cleaned_final[['Severity', column_name]]\n",
    "                          \n",
    "data_sev_temp = data_sev_temp.dropna()\n",
    "\n",
    "data_sev_temp = data_sev_temp.sort_values(by=['Severity'])\n",
    "\n",
    "#Extracting only numpy array with variable values\n",
    "\n",
    "data_sev_temp2 = data_sev_temp.drop(columns='Severity')\n",
    "\n",
    "\n",
    "#Getting ordinal variable numpy array for each variable value\n",
    "\n",
    "data_sev_temp = (data_sev_temp['Severity']).to_numpy()\n",
    "\n",
    "#Ordinal Logistic Regression\n",
    "\n",
    "from bevel.linear_ordinal_regression import OrderedLogit\n",
    "\n",
    "ls = OrderedLogit()\n",
    "ls.fit(data_sev_temp2, data_sev_temp)\n",
    "\n",
    "ls.print_summary()\n",
    "\n",
    "#Probability for each value to be in specific Severity group\n",
    "\n",
    "result = ls.predict_probabilities(data_sev_temp2)\n",
    "\n",
    "print(result[:][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability to be in Severity 4 analysis - UNIVERSAL\n",
    "\n",
    "column_name = input(\"Enter column name without brackets. Possible choices: \" + \n",
    "                    str(list(data_cleaned.columns)) + \" : \")\n",
    "\n",
    "#Extract array of column_name variable values\n",
    "\n",
    "variable_array = np.array(data_sev_temp2[column_name])\n",
    "print(variable_array)\n",
    "\n",
    "#Extract Probability Array Values\n",
    "\n",
    "list_res = []\n",
    "\n",
    "for i in range(0, len(result)):\n",
    "   list_res.append(result[i][3])\n",
    "\n",
    "Probability_array = np.array(list_res)\n",
    "print(Probability_array)\n",
    "\n",
    "\n",
    "#Linear Regression\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "variable_array_regression = variable_array.reshape((-1, 1))\n",
    "\n",
    "model = LinearRegression().fit(variable_array_regression, Probability_array)\n",
    "\n",
    "print(model)\n",
    "\n",
    "r_sq = model.score(variable_array_regression, Probability_array)\n",
    "intercept = model.intercept_\n",
    "slope = model.coef_\n",
    "\n",
    "\n",
    "#Line for plotting\n",
    "\n",
    "line = slope*variable_array+intercept\n",
    "print(line)\n",
    "\n",
    "#Create DataFrame from column_name variable and Probability\n",
    "\n",
    "pd_result = pd.DataFrame({column_name:variable_array, 'Probability':Probability_array})\n",
    "print(pd_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting probability in Severity group 4 and line chart of fitted linear regression model\n",
    "\n",
    "fig = px.scatter(pd_result, x=column_name, y=\"Probability\")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=variable_array,\n",
    "        y=line,\n",
    "        mode=\"lines\",\n",
    "        line=go.scatter.Line(color=\"gray\"),\n",
    "        showlegend=False)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print('Coefficient of determination (R^2 value): ' + str(r_sq))\n",
    "print('Slope : ' + str(slope))\n",
    "print('Intercept : ' + str(intercept))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
